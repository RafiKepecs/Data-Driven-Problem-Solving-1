{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jP3S6br8LU8V"
      },
      "source": [
        "# Regression\n",
        "\n",
        "## Table of Contents\n",
        "\n",
        "1. [**Introduction**](#Intro)   \n",
        "2. [**Non-Polynomial Regression**](#NonPoly)\n",
        "\n",
        "    2.1 [**Model Development**](#MDevNP)\n",
        "\n",
        "    2.2 [**Model Evaluation**](#MEvaNP)\n",
        "\n",
        "3. [**Polynomial Regression**](#PolyDev)\n",
        "\n",
        "    4.1 [**Model Development**](#MDevP)\n",
        "\n",
        "    4.2 [**Model Evaluation**](#MEvaP)\n",
        "\n",
        "4. [**Final Comments**](#FinalComments)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29lHK_5aLl36"
      },
      "source": [
        "## 1. Introduction <a name=\"Intro\"></a>\n",
        "\n",
        "Linear models are governed by equations that weight each feature variable by a coefficient reflecting its importance, and sum up these values. But all phenomenon can be descibed using linear models. Richer mathematical descriptions might be needed, including higher-order polynomials, logarithms, and exponentials. These permit models to fit the training data much more tightly than linear functions.\n",
        "\n",
        "That being said, more complicated models are not necessarily always better. Accoring to _Occam's razor_ __\"the simplest explanation is the best explanation.\"__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-P0hPEJOnO4"
      },
      "source": [
        "## 2. Non-Polynomial Regression <a name=\"NonPoly\"></a>\n",
        "\n",
        "We can fit any function to our data in Python environment. To do so, we just need to define the function and then use `curve_fit` function from <font color='blue'>scipy</font> library, module `optimize`, to find the coefficients."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTYTkFWErcIV"
      },
      "source": [
        "## 2.1 Model Development <a name=\"MDevNP\"></a>\n",
        "\n",
        "Here are the general steps you need to follow:\n",
        "\n",
        "__1.__ Import curve fitting package from scipy library. Also, import train_test_split funcion from <font color='blue'>scikit_learn</font> library:\n",
        "```python\n",
        "from scipy.optimize import curve_fit\n",
        "from sklearn.model_selection import train_test_split\n",
        "```\n",
        "\n",
        "__2.__ Define dependant (target variable) and independent variable (feature) from data set:\n",
        "```python\n",
        "x_data=df['column1']\n",
        "y_data=df['column2']\n",
        "```\n",
        "\n",
        "__3.__ Split the data into train and test sets: `x_train,x_test,y_train,y_test=train_test_split(x_data,y_data)`\n",
        "\n",
        "\n",
        "__4.__ Define the function you want to fit to the data:\n",
        "```python\n",
        "def my_func(inputs):\n",
        "  output=...\n",
        "  return output\n",
        "```\n",
        "\n",
        "__5.__ Use the `curve_fit` function to fit the function to the training data and find the coefficients:\n",
        "```python\n",
        "popt, pcov = curve_fit(my_func, x_train, y_train)\n",
        "```\n",
        "\n",
        "__6.__ Then, make predictions using the test data\n",
        "\n",
        "__7.__ Plot the training data, test data, and fitted curve to visually inspect the fit (optional)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJnefjH4_THV"
      },
      "source": [
        "Let's try this using a dataset representing strain rate sensitivity of cortical bone for longitudinal tensile loading. As with all biological materials, bone is viscoelastic and nonlinear. It has been shown that cortical bone is moderately strain-rate-dependent. This data is an excel sheet which includes stress-strain values for different strain rates.\n",
        "\n",
        "sheet1 name='StrainRate_0.001' (0.001 percent strain per second)\n",
        "\n",
        "sheet2 name='StrainRate_0.01'  (0.01 percent strain per second)\n",
        "\n",
        "sheet3 name='StrainRate_0.1'   (0.1 percent strain per second)\n",
        "\n",
        "sheet4 name='StrainRate_1'     (1 percent strain per second)\n",
        "\n",
        "sheet5 name='StrainRate_300'   (300 percent strain per second)\n",
        "\n",
        "sheet1 name='StrainRate_1500'  (1500 percent strain per second)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQLUpBvKLvgH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "xlsx = pd.ExcelFile('https://raw.githubusercontent.com/MasoudMiM/ME_364/master/StrainRate_CorticalBone/Cortical_Bone.xlsx')\n",
        "df = pd.read_excel(xlsx,sheet_name='StrainRate_0.001', names=['Strain %','Stress (MPa)'])            # 0.001 percent strain per second\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95K5s2GnVa8j"
      },
      "source": [
        "First, let's take a look at the data we imported"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dxyz8elyBhGC"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rcParams['font.size'] = '15'\n",
        "df.plot(kind='scatter',x='Strain %',y='Stress (MPa)',figsize=(7,5))\n",
        "plt.grid(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7CzJvcQVfrn"
      },
      "source": [
        "Now, let's define a function in the form of $y = a\\frac{bx}{100+bx}$, where $a$ and $b$ are constants, and use it for our curve fitting procedure."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usFoSQrHgykK"
      },
      "source": [
        "Steps __1__ and __2__, importing the libraries and defining the data for fitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQ3kD_wAbKmb"
      },
      "outputs": [],
      "source": [
        "from scipy.optimize import curve_fit\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1FtTP-bzbNLr"
      },
      "outputs": [],
      "source": [
        "x_data=df['Strain %']\n",
        "y_data=df['Stress (MPa)']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkcGqcEIg12Q"
      },
      "source": [
        "Step __3__, splitting the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMyXgCkZbU6q"
      },
      "outputs": [],
      "source": [
        "x_train,x_test,y_train,y_test=train_test_split(x_data,y_data,test_size=0.2,shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3TvVd8Gg_w3"
      },
      "source": [
        "Step __4__, defining the function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUdoaZu9X6LK"
      },
      "outputs": [],
      "source": [
        "def my_func(x,a,b):\n",
        "  output=a*(b*x/(100+b*x))\n",
        "  return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sw9dB29uhMbG"
      },
      "source": [
        "Step __5__, curve fitting and finding the coefficients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6k6Clfvbh2z"
      },
      "outputs": [],
      "source": [
        "popt, pcov = curve_fit(my_func, x_train, y_train)\n",
        "#print the final parameters\n",
        "print(f\" a = {popt[0]:.3f}, b = {popt[1]:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBqD15ZjhTIm"
      },
      "source": [
        "Step __6__, making predictions using test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vrZr4ycUcsmR"
      },
      "outputs": [],
      "source": [
        "yhat=my_func(x_test, popt[0], popt[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvsAPVcrhns_"
      },
      "source": [
        "Step __7__, plotting the fitted curve along with training and test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1n8HTtdccEg"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "plt.rcParams['font.size'] = '15'\n",
        "plt.figure(figsize=(8,7))\n",
        "\n",
        "# plotting the training data\n",
        "plt.scatter(x_train,y_train,color='blue',label='Training Data')\n",
        "\n",
        "# Plotting the test data\n",
        "plt.scatter(x_test,y_test,color='red',label='Test Data')\n",
        "\n",
        "# plottign the fitted curve\n",
        "xplot=np.linspace(0,max(x_train),num=50)\n",
        "yplot=my_func(xplot,popt[0],popt[1])\n",
        "plt.plot(xplot,yplot,color='green', lw=3,label='Fitted Curve')\n",
        "\n",
        "# plots labeling and legend\n",
        "plt.xlabel('Strain (%)')\n",
        "plt.ylabel('Stress (MPa)')\n",
        "plt.legend(loc='best');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrovkGPAO4og"
      },
      "source": [
        "## 2.2 Model Evaluation <a name=\"MEvaNP\"></a>\n",
        "\n",
        "To evalulate our model, we need to find and compare the errors for the test data. We are going to use Mean Squared Error (MSE) and R-Squared (R$^2$) for evaluating the performance of the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4H_VnymOwr-P"
      },
      "outputs": [],
      "source": [
        "# Mean Squared Error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "MSETst=mean_squared_error(y_test,yhat)\n",
        "print(f'The value of mean squared error is: {MSETst:0.3f}')\n",
        "\n",
        "# R2\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "r2scoreTst = r2_score(y_test,yhat)\n",
        "print(f'The value of R2 is: {r2scoreTst:0.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOq6zZBZr-Pa"
      },
      "source": [
        "Let's make a change in the function we used to fit the data and see how the performance changes. \n",
        "\n",
        "This time using the function Using $y=a\\left(1-e^{-bx}\\right)$, we get"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHkeWZAssExx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def my_func2(x,a,b):\n",
        "  output=a*(1-np.exp(-b*x))\n",
        "  return output\n",
        "\n",
        "popt2, pcov2 = curve_fit(my_func2, x_train, y_train)\n",
        "#print the final parameters\n",
        "print(f\" a = {popt2[0]:0.3f}, b = {popt2[1]:0.3f}\")\n",
        "\n",
        "yhat2=my_func2(x_test, popt2[0], popt2[1])\n",
        "\n",
        "plt.rcParams['font.size'] = '15'\n",
        "plt.figure(figsize=(8,7))\n",
        "\n",
        "# plotting the training data\n",
        "plt.scatter(x_train,y_train,color='blue',label='Train Data')\n",
        "\n",
        "# Plotting the test data\n",
        "plt.scatter(x_test,y_test,color='red',label='Train Data')\n",
        "\n",
        "# plottign the fitted curve\n",
        "xplot2=np.linspace(0,1.75,num=50)\n",
        "yplot2=my_func2(xplot,popt2[0],popt2[1])\n",
        "plt.plot(xplot2,yplot2,color='green', lw=3,label='Fitted Curve')\n",
        "\n",
        "# plots labeling and legend\n",
        "plt.xlabel('Strain (%)')\n",
        "plt.ylabel('Stress (MPa)')\n",
        "plt.legend(loc='best');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bns5ym0Fs-le"
      },
      "source": [
        "Let's evaluate this model now"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATFRw50DtCAu"
      },
      "outputs": [],
      "source": [
        "# Mean Squared Error\n",
        "MSE2=mean_squared_error(y_test, yhat2)\n",
        "print(f'The value of mean squared error is: {MSE2:0.3f}')\n",
        "\n",
        "# R2\n",
        "r2score2 = r2_score(y_test,yhat2)\n",
        "print(f'The value of R2 is: {r2score2:0.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBA2E36aMH6Q"
      },
      "source": [
        "## 3. Polynomial Regression <a name=\"PolyDev\"></a>\n",
        "\n",
        "Following our lecture, we convert the polynomial into a multiple linear regression. This process in Python can be done using `PloynomialFeatures` function in <font color='blue'>scikit-learn</font> library, which derives a new feature sets from the original feature set.\n",
        "\n",
        "Once we transform the polynomial, we can follow the same steps that we did for multiple linear regression (previous class) to develop a regression model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxIByNS_Rpww"
      },
      "source": [
        "## 3.1 Model Development <a name=\"MDevP\"></a>\n",
        "\n",
        "Here are the steps to implement polynomial regression in Python using scikit-learn.\n",
        "\n",
        "__1.__ Import Numpy, PolynomialFeatures, LinearRegression and train_test_split funcions from <font color='blue'>scikit_learn</font> library:\n",
        "```python\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "```\n",
        "\n",
        "__2.__ Define dependant variable (target variable) and independent variable (feature) from data set:\n",
        "```python\n",
        "x_data=np.array(df[['column1']])\n",
        "y_data=np.array(df[['column2']])\n",
        "```\n",
        "\n",
        "__3.__ Split the data into train and test sets: `x_train,x_test,y_train,y_test=train_test_split(x_data,y_data)`\n",
        "\n",
        "__4.__ Transform the training and test data using PolynomialFeatures() function and knowing the degree of polynomial you want.\n",
        "```python\n",
        "poly = PolynomialFeatures(degree=2)  # for a 2 degrre polynomial\n",
        "x_train_transformed = poly.fit_transform(x_train)\n",
        "x_test_transformed = poly.fit_transform(x_test)\n",
        "```\n",
        "\n",
        "__5.__ Create a linear regression object using the constructor: `lmPoly = LinearRegression() `\n",
        "\n",
        "\n",
        "__6.__ Use the fit function to fit the model to the training data and find the coefficients: `lmPoly.fit(x_train_transformed, y_train)`\n",
        "\n",
        "__7.__ Then, make prediction using the test data and training data:\n",
        "```python\n",
        "yhatTest =lmPoly.predict(x_test_transformed)\n",
        "yhatTrain=lmPoly.predict(x_train_transformed)\n",
        "```\n",
        "\n",
        "__8.__ Plot the training data, test data, and fitted curve to visually inspect the fit (optional)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CooUn8pBTpnr"
      },
      "source": [
        "Before going further, I recomend cleaning the memory and clear all the variables defined in this notebook so far..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CqC1juwLTzGA"
      },
      "outputs": [],
      "source": [
        "%reset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zuy53SmSbV6F"
      },
      "source": [
        "Let's bring our 3D printer data set and use that for model development.\n",
        "\n",
        "Parameters:\n",
        "\n",
        "- Layer Height (mm)\n",
        "\n",
        "- Wall Thickness (mm)\n",
        "\n",
        "- Infill Density (%)\n",
        "\n",
        "- Infill Pattern ()\n",
        "\n",
        "- Nozzle Temperature (Cº)\n",
        "\n",
        "- Bed Temperature (Cº)\n",
        "\n",
        "- Print Speed (mm/s)\n",
        "\n",
        "- Material ()\n",
        "\n",
        "- Fan Speed (%)\n",
        "\n",
        "- Roughness (µm)\n",
        "\n",
        "- Tnesile (ultimate) Strenght (MPa)\n",
        "\n",
        "- Elongation (%) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wc_LclYlRrYL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/MasoudMiM/ME_364/main/3D_Printer_Data/3DPrinterDataset.csv'   # Link to the 3D printer data set\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKBZ3P7RbxRS"
      },
      "source": [
        "Just as a quick look at the data, I am going to use `pairplot` function from <fonr color='blue'> seaborn </font> library. (this might take a few minutes to run)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JK6kxg0bb8L7"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "sns.pairplot(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0B2oa6KKc9C-"
      },
      "source": [
        "Let us take a look at roughness and layer height. We try to train a model to predict roughness based on the layer height."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3f2L5_UdiMO"
      },
      "source": [
        "Steps __1__ and __2__, importing required modules and functions as well as defining the variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ygE3w0ndqsF"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0CsZkyxdsYl"
      },
      "outputs": [],
      "source": [
        "x_dataPoly=np.array(df[['layer_height']])\n",
        "y_dataPoly=np.array(df[['roughness']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RmnvmQReNQ0"
      },
      "source": [
        "Step __3__, splitting the data into test and train data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6720wVAfFPy"
      },
      "outputs": [],
      "source": [
        "x_trainP,x_testP,y_trainP,y_testP=train_test_split(x_dataPoly, y_dataPoly, test_size=0.2, random_state=125)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHtEZ4Aufe4i"
      },
      "source": [
        "Step __4__, transforming the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RvDix3mCfhxh"
      },
      "outputs": [],
      "source": [
        "poly = PolynomialFeatures(degree=2)  # for a 2nd degree polynomial\n",
        "x_train_transformed = poly.fit_transform(x_trainP)\n",
        "x_test_transformed = poly.fit_transform(x_testP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEjVKP1dfnnZ"
      },
      "source": [
        "Step __5__, create a linear regression instance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XlPlsTzIfujp"
      },
      "outputs": [],
      "source": [
        "lmPoly = LinearRegression()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vq9UNYzfqoJ"
      },
      "source": [
        "Step __6__, use the fit function to fit the model to the training data and find the coefficients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OKljEoIBf7bK"
      },
      "outputs": [],
      "source": [
        "lmPoly.fit(x_train_transformed, y_trainP)\n",
        "\n",
        "# printing the coefficients\n",
        "print('w_0=',lmPoly.intercept_[0],',w_1=',lmPoly.coef_[0][1], ', and w_2=',lmPoly.coef_[0][2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wJT7ptJxxFR"
      },
      "source": [
        "Step __7__, make predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CwY-4a15x0DW"
      },
      "outputs": [],
      "source": [
        "yhatPt=lmPoly.predict(x_test_transformed)   # using testing data\n",
        "yhatPTr=lmPoly.predict(x_train_transformed) # using training data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SD1WoBRO0EXu"
      },
      "source": [
        "Step __8__, plotting the fitted curve, training data, and test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDBHN6ZugGqP"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# figure size and font size\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.rc('font',size=16)\n",
        "\n",
        "# Plotting the fitted curve\n",
        "xplotP=np.linspace(0.025,0.2,num=40)\n",
        "yplotP=lmPoly.intercept_[0]+lmPoly.coef_[0][1]*xplotP+lmPoly.coef_[0][2]*xplotP**2\n",
        "plt.plot(xplotP,yplotP,color='green', lw=3, label='Fitted Curve')\n",
        "\n",
        "# Plotting the training data\n",
        "plt.scatter(x_trainP,y_trainP,color='blue',s=80, label='Training Data')\n",
        "\n",
        "# Plotting the test data\n",
        "plt.scatter(x_testP,y_testP,color='red',s=80, label='Test Data')\n",
        "\n",
        "# Plot labels and legend\n",
        "plt.xlabel('Elongation (%)')\n",
        "plt.ylabel('Roughness (micro-meter)')\n",
        "plt.legend(loc='best');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBCQdNp2jGFD"
      },
      "source": [
        "Let's now do the same process and use a higher order polynomial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QyzHk0pxjNQ6"
      },
      "outputs": [],
      "source": [
        "# Defining the polynomial and fit it into the data\n",
        "poly4 = PolynomialFeatures(degree=4)  # for a 4th degree polynomial\n",
        "x_train_transformedP4 = poly4.fit_transform(x_trainP)\n",
        "x_test_transformedP4 = poly4.fit_transform(x_testP)\n",
        "lmPoly4 = LinearRegression()\n",
        "lmPoly4.fit(x_train_transformedP4, y_trainP)\n",
        "\n",
        "# Predictions\n",
        "yhatP4t=lmPoly4.predict(x_test_transformedP4)\n",
        "yhatP4Tr=lmPoly4.predict(x_train_transformedP4)\n",
        "\n",
        "# figure size and font size\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.rc('font',size=16)\n",
        "\n",
        "# Plotting the fitted curve\n",
        "yplotP4=lmPoly4.intercept_[0]+lmPoly4.coef_[0][1]*xplotP+lmPoly4.coef_[0][2]*xplotP**2+lmPoly4.coef_[0][3]*xplotP**3+lmPoly4.coef_[0][4]*xplotP**4\n",
        "plt.plot(xplotP,yplotP4,color='green', lw=3, label='Fitted Curve')\n",
        "\n",
        "# Plotting the training data\n",
        "plt.scatter(x_trainP,y_trainP,color='blue',s=80, label='Training Data')\n",
        "\n",
        "# Plotting the test data\n",
        "plt.scatter(x_testP,y_testP,color='red',s=80, label='Test Data')\n",
        "\n",
        "# Plot labels and legend\n",
        "plt.xlabel('Elongation (%)')\n",
        "plt.ylabel('Roughness (micro-meter)')\n",
        "plt.legend(loc='best');\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VvXVYysRuWj"
      },
      "source": [
        "## 3.2 Model Evaluation <a name=\"MEvaP\"></a>\n",
        "\n",
        "Let us evaluate our models using relative squared error (RSE). I start with the 2$^{nd}$ degree polynomial regression. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YURiMolwnlV"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "## Evaluation using test data\n",
        "rse2ndp_test = 1-r2_score(y_testP, yhatPt)\n",
        "print('The value of RSE for test data for 2nd degree polynomial regression is: %.2f\\n' %rse2ndp_test)\n",
        "\n",
        "# Evaluation using train data\n",
        "rse2ndp_train = 1-r2_score(y_trainP, yhatPTr)\n",
        "print('The value of RSE for training data for 2nd degree polynomial regression is: %.2f' %rse2ndp_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDNCdL0tzLzE"
      },
      "source": [
        "Now, let's take a look at RSE for 4$^{th}$ degree polynomial regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ub_oKt-DzTB9"
      },
      "outputs": [],
      "source": [
        "## Evaluation using test data\n",
        "rse4thp_test = 1-r2_score(y_testP,yhatP4t)\n",
        "print('The value of RSE for test data for 4th degree polynomial regression is: %.2f' %rse4thp_test)\n",
        "\n",
        "print('')\n",
        "# Evaluation using train data\n",
        "rse4thp_train = 1-r2_score(y_trainP,yhatP4Tr)\n",
        "print('The value of RSE for training data for 4th degree polynomial regression is: %.2f' %rse4thp_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7qaO3WE08Mv"
      },
      "source": [
        "Let's try to do the regression process for polynomials with different degrees, find the relative squared errors of training and test data for each."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99j8oS7NRwDL"
      },
      "outputs": [],
      "source": [
        "degreep=[0,1,2,3,4,5,6]\n",
        "rsePolyNom_test=np.zeros((len(degreep),1))\n",
        "rsePolyNom_train=np.zeros((len(degreep),1))\n",
        "\n",
        "for ii,deg in enumerate(degreep):\n",
        "  # Defining the polynomial and fit it into the data\n",
        "  polyNom = PolynomialFeatures(degree=deg) \n",
        "  x_train_transformedPolyNm = polyNom.fit_transform(x_trainP)\n",
        "  x_test_transformedPolyNm = polyNom.fit_transform(x_testP)\n",
        "  lmPolyNom = LinearRegression()\n",
        "  lmPolyNom.fit( x_train_transformedPolyNm , y_trainP)\n",
        "  \n",
        "  # calculating rse for test data\n",
        "  yhatPolyNomTS=lmPolyNom.predict(x_test_transformedPolyNm)\n",
        "  rsePolyNom_test[ii]=1-r2_score(y_testP,yhatPolyNomTS)\n",
        "\n",
        "  # calculating rse for training data\n",
        "  yhatPolyNomTR=lmPolyNom.predict(x_train_transformedPolyNm)\n",
        "  rsePolyNom_train[ii]=1-r2_score(y_trainP,yhatPolyNomTR)\n",
        "\n",
        "print('Test Errors:')\n",
        "print(rsePolyNom_test)\n",
        "print('')\n",
        "print('Train Errors:')\n",
        "print(rsePolyNom_train)\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.rc('font',size=12)\n",
        "plt.plot(degreep,rsePolyNom_test,'-o',degreep,rsePolyNom_train,'-o', linewidth=2,markersize=10)\n",
        "plt.xlabel('Polynomial Degree')\n",
        "plt.ylabel('Relative Squared Error')\n",
        "plt.legend(['Test Data','Training Data']);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-sjwCpZBG2Y"
      },
      "source": [
        "Let's plot these polynomials and see what do they look like"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAKtr32qBTeR"
      },
      "outputs": [],
      "source": [
        "degreep=[1,2,3,4,5,6]\n",
        "\n",
        "# setting figure size and font size\n",
        "fig=plt.figure(figsize=(15,8))\n",
        "plt.rc('font',size=8)\n",
        "\n",
        "# For plotting the fitted curve\n",
        "xplotP=np.linspace(0.025,0.2,num=40)\n",
        "\n",
        "for ii, deg in enumerate(degreep):\n",
        "  fig.add_subplot(2,3,ii+1)\n",
        "  \n",
        "  # Defining the polynomial and fit it into the data\n",
        "  polyNomp = PolynomialFeatures(degree=deg) \n",
        "  x_train_transformedPolyNmp = polyNomp.fit_transform(x_trainP)\n",
        "  x_test_transformedPolyNmp = polyNomp.fit_transform(x_testP)\n",
        "  lmPolyNomp = LinearRegression()\n",
        "  lmPolyNomp.fit( x_train_transformedPolyNmp , y_trainP )\n",
        "\n",
        "  yplottmp=np.zeros((xplotP.shape))\n",
        "  yplotP=np.zeros((xplotP.shape))\n",
        "\n",
        "  for jj in range(deg):\n",
        "    yplottmp=yplottmp+lmPolyNomp.coef_[0][jj+1]*xplotP**(jj+1)\n",
        "\n",
        "  print('')\n",
        "  yplotP=lmPolyNomp.intercept_[0]+yplottmp\n",
        "  plt.plot(xplotP,yplotP,color='green', lw=3, label='Fitted Curve')\n",
        "  \n",
        "  # Plotting the training data\n",
        "  plt.scatter(x_trainP,y_trainP,color='blue',s=80, label='Training Data')\n",
        "  \n",
        "  # Plotting the test data\n",
        "  plt.scatter(x_testP,y_testP,color='red',s=80, label='Test Data')\n",
        "  \n",
        "  # Plot labels and legend\n",
        "  plt.title('{}-order polynomial'.format(deg))\n",
        "  plt.xlabel('Elongation (%)')\n",
        "  plt.ylabel('Roughness (micro-meter)')\n",
        "  plt.legend(loc='best')\n",
        "\n",
        "  # set the spacing between subplots\n",
        "plt.subplots_adjust(top=0.8, wspace=0.4, hspace=0.4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yQtVGdIRzmb"
      },
      "source": [
        "## 4. Final Comments <a name=\"FinalComments\"></a>\n",
        "\n",
        "When we are developing a regression model, we need to look at the errors for both training data and test data. Keep in mind that simple models can underfit the data while more complicated models can overfit the data. When the model underfits the data, we have high bias and when the model overfits the data, we have high variance. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "9_NonLinear_Regression.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
