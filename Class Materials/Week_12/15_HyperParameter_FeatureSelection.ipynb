{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyBmm0gi8yqR"
      },
      "source": [
        "# Hyperparameter Tuning and Feature Selection\n",
        "\n",
        "## Table of Contents\n",
        "\n",
        "1. [**Introduction**](#Intro)\n",
        "2. [**Cross-Validation**](#CrossVal)\n",
        "3. [**Hyperparameter Tuning**](#HyperTun)\n",
        "\n",
        "    3.1. [**Grid Search**](#GridSrch)\n",
        "\n",
        "    3.2. [**Random Search**](#RandSrch)\n",
        "\n",
        "4. [**Feature Selection**](#FeatureSlc)\n",
        "\n",
        "    4.1. [**Feature Importance**](#FImport)\n",
        "  \n",
        "    4.2. [**Recursive Feature Elimination**](#RFE)\n",
        "\n",
        "  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2SR5BLm9Uu2"
      },
      "source": [
        "# 1 Introduction <a name=\"Intro\"></a>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2a28cSAe3em"
      },
      "source": [
        "In this notebook, we will cover some aspects related to fine tuning a model. First, we introduce cross-validation and how it can be used for the evaluation of the performance of a model. Then, we look into hypterparameter tuning using grid search and random search. Finally, a brief discussion on feature selection and how to identify the most imprtant features for model development."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LL_WBZf3A_V2"
      },
      "source": [
        "# 2 Cross-Validation <a name=\"CrossVal\"></a>\n",
        "\n",
        "\n",
        "The procedure has a single parameter called k that refers to the number of groups that a given data sample is to be split into. As such, the procedure is often called k-fold cross-validation. When a specific value for k is chosen, it may be used in place of k in the reference to the model, such as k=10 becoming 10-fold cross-validation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WI51Sx6K75yH"
      },
      "source": [
        "A value of __k=10__ is very common in the field of applied machine learning, and is recommend if you are struggling to choose a value for your dataset. The reason for this is studies were performed and k=10 was found to provide good trade-off of low computational cost and low bias in an estimate of model performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZMCjV0g8e62"
      },
      "source": [
        "Let's try it out using a logistic regression model. We are going to use the steel manufacturing data that we have seen before."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GikFvHWeAoWE"
      },
      "source": [
        "Steel plate faults dataset is provided by Semeion, Research of Sciences of Communication, Via Sersale 117, 00128, Rome, Italy. In this dataset, the faults of steel plates are classified into 7 types. Since it has been donated on October 26,2010, this dataset has been widely used in machine learning for automatic pattern recognition. Types of fault and corresponding numbers of sample are shown in the table below\n",
        "\n",
        "<img src=\"https://docs.google.com/uc?export=download&id=1pw1oJ7plDsTASg_ntI_QSVivQ-tMhlqq\" width=\"500\">\n",
        "\n",
        "\n",
        "The numbers of sample vary a lot from one category to another. Meanwhile, fault 7 is a special class because it contains all other faults except the first six kinds of fault. In other words, samples in class 7 may have no obvious common characteristics. For every sample, 27 features are recorded, providing evidences for its fault class. All attributes are expressed by integers or real numbers. Detailed information about these 27 independent variables is listed out in the following table.\n",
        "\n",
        "<img src=\"https://docs.google.com/uc?export=download&id=1lAV-mPa2seL9VWkezbaCicnZVwOup2c6\" width=\"500\">\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9NlnjF14Avjx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "url = ('https://raw.githubusercontent.com/MasoudMiM/ME_364/main/Steel_Plates_Faults/Data.csv')\n",
        "df = pd.read_csv(url,names=['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas', 'X_Perimeter',\n",
        "                            'Y_Perimeter', 'Sum_of_Luminosity', 'Minimum_of_Luminosity', 'Maximum_of_Luminosity',\n",
        "                            'Length_of_Conveyer', 'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n",
        "                            'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index', 'Edges_X_Index',\n",
        "                            'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas', 'Log_X_Index', 'Log_Y_Index',\n",
        "                            'Orientation_Index', 'Luminosity_Index', 'SigmoidOfAreas', 'Pastry', 'Z_Scratch',\n",
        "                            'K_Scratch', 'Stains', 'Dirtiness', 'Bumps', 'Other_Faults'])           \n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJqwtvhxAyt4"
      },
      "outputs": [],
      "source": [
        "Features = ['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas', 'X_Perimeter',\n",
        "             'Y_Perimeter', 'Sum_of_Luminosity', 'Minimum_of_Luminosity', 'Maximum_of_Luminosity',\n",
        "             'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness']\n",
        "             \n",
        "x_data=np.array(df[Features])\n",
        "y_data=df['Stains']\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(x_data,y_data,test_size=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nGiBCUp1AYGX"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold  \n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# prepare the cross-validation procedure\n",
        "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
        "# By setting the random_state argument, it ensures that we get \n",
        "# the same randomly generated examples each time the code is run.\n",
        "\n",
        "# create model\n",
        "model = LogisticRegression()\n",
        "\n",
        "# evaluate model\n",
        "scores = cross_val_score(model, x_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "\n",
        "# report performance\n",
        "print(f'Accuracy: {np.mean(scores)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hai0PooTRza7"
      },
      "outputs": [],
      "source": [
        "scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXhLhbVNDC9P"
      },
      "source": [
        "we can split a dataset randomly in such a way that maintains the same class distribution in each subset. This is called __stratification__ or __stratified__ sampling. we can use a version of k-fold cross-validation that preserves the imbalanced class distribution in each fold. It is called __stratified k-fold cross-validation__ and will enforce the class distribution in each split of the data to match the distribution in the complete training dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWOtza3sEX18"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print('Target variable distribution in training data:')\n",
        "print( y_train.value_counts() )\n",
        "fig = plt.figure(figsize=(15,4))\n",
        "fig.add_subplot(1,2,1)\n",
        "y_train.value_counts().plot(kind='barh')\n",
        "plt.title('Training Data')\n",
        "\n",
        "print('Target variable distribution in test data:')\n",
        "print( y_test.value_counts() )\n",
        "fig.add_subplot(1,2,2)\n",
        "y_test.value_counts().plot(kind='barh')\n",
        "plt.title('Test Data');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlexEO80EAXc"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# prepare the cross-validation procedure\n",
        "cv = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n",
        "# By setting the random_state argument, it ensures that we get \n",
        "# the same randomly generated examples each time the code is run.\n",
        "\n",
        "# create model\n",
        "model = LogisticRegression(solver= 'newton-cg', penalty='l2', C = 5e-06)\n",
        "\n",
        "# evaluate model\n",
        "scores = cross_val_score(model, x_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "\n",
        "# report performance\n",
        "print(f'Accuracy: {np.mean(scores)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJFc4eFhTyjF"
      },
      "source": [
        "# 3 Hyperparameter Tuning <a name=\"HyperTun\"></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tj5UKgIsJCPo"
      },
      "source": [
        "## 3.1 Grid Search <a name=\"GridSrch\"></a>\n",
        "\n",
        "A point in the search space is a vector with a specific value for each hyperparameter value. The goal of the optimization procedure is to find a vector that results in the best performance of the model after learning, such as maximum accuracy or minimum error.\n",
        "\n",
        "We can use scikit-learn `GridSearchCV` to perform this task. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgRRt91wDOA5"
      },
      "source": [
        "We can perform a grid search for __SVM__ hyperparameters for example.\n",
        "\n",
        "Recall the SVM had two important hyperparameters, `C` and `gamma`. \n",
        "\n",
        "- <font color='red'> __C__ </font> (Regularization Parameter) tells the SVM optimization how much you want to avoid misclassifying each training example. If __C__ is high, the optimization will choose smaller margin hyperplane, so training data misclassification rate will be low. On the other hand, if __C__ is low, then the margin will be big, even if there will be misclassified training data examples.\n",
        "\n",
        "<img src=\"https://docs.google.com/uc?export=download&id=1B0ZEQqulcumqQBhSqtD18gnbWS87Z1SS\" width=\"900\">\n",
        "\n",
        "(ref for figure: https://www.vebuso.com/2020/03/svm-hyperparameter-tuning-using-gridsearchcv)\n",
        "\n",
        "- <font color='red'> __Gamma__ </font>: The gamma parameter defines how far the influence of a single training example reaches. This means that high Gamma will consider only points close to the plausible hyperplane and low Gamma will consider points at greater distance. This parameter comes into play if only kernels 'rbf', 'poly' and 'sigmoid' are used.\n",
        "\n",
        "<img src=\"https://docs.google.com/uc?export=download&id=18ioDU_qX_fCKw-fnAVBapBfUnqgd1nHF\" width=\"900\">\n",
        "\n",
        "(ref for figure: https://www.vebuso.com/2020/03/svm-hyperparameter-tuning-using-gridsearchcv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMmbRlyQDOA5"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# define model\n",
        "model = SVC()\n",
        "\n",
        "# define evaluation\n",
        "cv = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n",
        "\n",
        "# define search space\n",
        "space = dict()\n",
        "#space['kernel'] = ['rbf', 'poly']\n",
        "space['gamma'] = [1, 0.1, 0.01]\n",
        "space['C'] = [0.1, 1]\n",
        "\n",
        "# define search\n",
        "search = GridSearchCV(model, space, scoring='accuracy', n_jobs=-1, cv=cv)\n",
        "\n",
        "# execute search\n",
        "result = search.fit(x_train, y_train)\n",
        "\n",
        "# summarize result\n",
        "print(f'Best Score: {result.best_score_}')\n",
        "print(f'Best Hyperparameters: {result.best_params_}' )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoDG_h8PDOA5"
      },
      "source": [
        "As another example, we can look at Logistic Regression. For this algorithm, we can search for the best values for the numerical solver, the penalty term (which could be `L1` or `L2` norms or a combination `elasticnet`).\n",
        "\n",
        "Recall the regularization terms:\n",
        "\n",
        "$L_1=\\frac{1}{C} \\sum_{i=1}^{n}|w_i|$\n",
        "\n",
        "$L_2=\\frac{1}{C} \\sum_{i=1}^{n}w_i^2$\n",
        "\n",
        "In logistic regression implementation, regularization strength is determined by parameter `C`. From the relationships, smaller values specify stronger regularization.\n",
        "\n",
        "\n",
        "Let's try Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cW74fg2uLTmm"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# define model\n",
        "model = LogisticRegression()\n",
        "\n",
        "# define evaluation\n",
        "cv = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n",
        "\n",
        "# define search space\n",
        "space = dict()\n",
        "space['solver'] = ['newton-cg', 'lbfgs', 'liblinear']\n",
        "space['penalty'] = ['none', 'l1', 'l2', 'elasticnet']\n",
        "space['C'] = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100]\n",
        "\n",
        "# define search\n",
        "search = GridSearchCV(model, space, scoring='accuracy', n_jobs=-1, cv=cv)\n",
        "\n",
        "# execute search\n",
        "result = search.fit(x_train, y_train)\n",
        "\n",
        "# summarize result\n",
        "print(f'Best Score: {result.best_score_}')\n",
        "print(f'Best Hyperparameters: {result.best_params_}' )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2loJ_mhlN2sQ"
      },
      "source": [
        "## 3.2 Random Search <a name=\"RandSrch\"></a>\n",
        "\n",
        "We can use scikit-learn `RandomizedSearchCV` to perform this task. We must set the number of iterations or samples to draw from the search space via the `n_iter` argument."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brNFusO0DOA6"
      },
      "source": [
        "For SVM as an example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlAhLiWkDOA6"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# define model\n",
        "model = SVC()\n",
        "\n",
        "# define evaluation\n",
        "cv = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n",
        "\n",
        "# define search space\n",
        "space = dict()\n",
        "#space['kernel'] = ['rbf', 'poly']\n",
        "space['gamma'] = [1, 0.1, 0.01, 0.001]\n",
        "space['C'] = [0.1, 1, 10, 100]\n",
        "\n",
        "# define search\n",
        "search = RandomizedSearchCV(model, space, n_iter=10, scoring='accuracy', n_jobs=-1, cv=cv, random_state=1)\n",
        "\n",
        "# execute search\n",
        "result = search.fit(x_train, y_train)\n",
        "\n",
        "# summarize result\n",
        "print(f'Best Score: {result.best_score_}')\n",
        "print(f'Best Hyperparameters: {result.best_params_}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNZ69HQrDOA6"
      },
      "source": [
        "For logistic Regression as another example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YcIGvAcMQKix"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# define model\n",
        "model = LogisticRegression()\n",
        "\n",
        "# define evaluation\n",
        "cv = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n",
        "\n",
        "space = dict()\n",
        "space['solver'] = ['newton-cg', 'lbfgs', 'liblinear']\n",
        "space['penalty'] = ['none', 'l1', 'l2', 'elasticnet']\n",
        "space['C'] = [1e-6, 5e-6, 1e-5, 5e-5, 1e-4, 5e-4, 1e-3, 5e-3, 1e-2, \n",
        "              5e-2, 1e-1, 5e-1, 1, 5, 10, 50, 100, 500, 10000]\n",
        "\n",
        "# define search\n",
        "search = RandomizedSearchCV(model, space, n_iter=20, scoring='accuracy', n_jobs=-1, cv=cv, random_state=1)\n",
        "\n",
        "# execute search\n",
        "result = search.fit(x_train, y_train)\n",
        "\n",
        "# summarize result\n",
        "print(f'Best Score: {result.best_score_}')\n",
        "print(f'Best Hyperparameters: {result.best_params_}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCE0akZr38kl"
      },
      "source": [
        "# 4 Feature Selection <a name=\"FeatureSlc\"></a>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ua_7FBOMVlL1"
      },
      "source": [
        "\"feature selection… is the process of selecting a subset of relevant features for use in model construction\". Also, \"Feature selection is itself useful, but it mostly acts as a filter, muting out features that aren’t useful in addition to your existing features.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9K0GAy_XS3f"
      },
      "source": [
        "## 4.1 Feature Importance <a name=\"FImport\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVPColIZhN2P"
      },
      "source": [
        "Using __logistic__ regression model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmW34450PAjD"
      },
      "outputs": [],
      "source": [
        "# define the model\n",
        "model = LogisticRegression()\n",
        "# fit the model\n",
        "model.fit(x_train, y_train)\n",
        "# get importance\n",
        "importance = model.coef_[0]\n",
        "print(importance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ORxk6iEkHMD"
      },
      "outputs": [],
      "source": [
        "# summarize feature importance\n",
        "for rank, feature in sorted(zip(Features,importance,)):\n",
        "  print(rank,feature)\n",
        "\n",
        "# plot feature importance\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.bar([x for x in range(len(importance))], importance)\n",
        "plt.xticks(ticks=range(len(importance)), labels=Features, rotation=90)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QT9o9ZnW5SJ"
      },
      "source": [
        "## 4.2 Recursive Feature Elimination (RFE) <a name=\"RFE\"></a>\n",
        "\n",
        "RFE is popular because it is easy to configure and use and because it is effective at selecting those features (columns) in a training dataset that are more or most relevant in predicting the target variable.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9vAmahrYFyf"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.feature_selection import RFE\n",
        "\n",
        "# define the method\n",
        "rfe = RFE(estimator=LogisticRegression(), n_features_to_select=5)\n",
        "# fit the model\n",
        "rfe.fit(x_train, y_train)\n",
        "\n",
        "# evaluate model\n",
        "cv = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n",
        "\n",
        "n_scores = cross_val_score(rfe, x_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "# report performance\n",
        "print(f'Accuracy: {np.mean(n_scores)}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uA7UHorObkTU"
      },
      "source": [
        "We can also look a the ranking for the features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbnLs0OPZmDN"
      },
      "outputs": [],
      "source": [
        "Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZeKw8YlHZiBW"
      },
      "outputs": [],
      "source": [
        "for rank, feature in sorted(zip(rfe.ranking_,Features)):\n",
        "  print(rank,feature)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "15_HyperParameter_FeatureSelection.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}