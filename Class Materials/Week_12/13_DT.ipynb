{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HTfFCjZLMGU"
      },
      "source": [
        "# Decision Tree\n",
        "\n",
        "## Table of Contents\n",
        "\n",
        "1. [**Introduction**](#Intro)  \n",
        "    \n",
        "2. [**Model Development Procedure**](#ModelDevp)\n",
        "   \n",
        "3. [**Model Development and Evaluation**](#Class)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaFcMGqILcti"
      },
      "source": [
        "## 1 Introduction <a name=\"Intro\"></a>\n",
        "\n",
        "A decision tree is a flowchart-like tree structure where: \n",
        "\n",
        "- Each internal node (decision node) denotes a test on an feature\n",
        "- Each branch represents an outcome of the test\n",
        "- Each leaf node (or terminal node) holds a class label\n",
        "- The topmost node is the root node\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rru65eselOgw"
      },
      "source": [
        "## 2 Model Development Procedure <a name=\"ModelDevp\"></a>\n",
        "\n",
        "Here are the steps to implement logistic regression in Python using <font color='blue'>scikit-learn</font> library\n",
        "\n",
        "__1.__ Import `DecisionTreeClassifier`, `train_test_split`, and `MinMaxScaler` funcions from scikit learn library along with `numpy` library\n",
        "```python\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler  # For normalization\n",
        "import numpy as np\n",
        "```\n",
        "\n",
        "__2.__ Define dependant (target variable) and independent variable (feature) from data set:\n",
        "```python\n",
        "x_data=np.array(df[['feature1','feature2',...]])\n",
        "y_data=df['target variable']\n",
        "```\n",
        "\n",
        "__3.__ Normalize your data using <font color='blue'>MinMaxScaler</font> (Optional but advised)\n",
        "```python\n",
        "MinMaxscaler = MinMaxScaler()  # define min max scaler\n",
        "x_data_scaled = MinMaxscaler.fit_transform(x_data)  # transform data\n",
        "```\n",
        "\n",
        "__4.__ Split the data into train and test sets: `x_train,x_test,y_train,y_test=train_test_split(x_data_scaled,y_data)`\n",
        "\n",
        "\n",
        "\n",
        "__5.__ Create a decision tree object using the constructor: `dt = DecisionTreeClassifier() `\n",
        "\n",
        "\n",
        "__6.__ Use the fit function to fit the model to the training data: `dt.fit(x_train,y_train)`\n",
        "\n",
        "__7.__ Then, make prediction using the test data and training data:\n",
        "```python\n",
        "yhatTest=dt.predict(x_test)\n",
        "yhatTrain=dt.predict(x_train)\n",
        "```\n",
        "\n",
        "__8.__ Create visualizations (Optional)\n",
        "\n",
        "__9.__ Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLOjJDo1ofG2"
      },
      "source": [
        "## 3 Model Developement and Evaluation<a name=\"Class\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTIKRUJX6UKK"
      },
      "source": [
        "Steel plate faults dataset is provided by Semeion, Research of Sciences of Communication, Via Sersale 117, 00128, Rome, Italy. In this dataset, the faults of steel plates are classified into 7 types. Since it has been donated on October 26,2010, this dataset has been widely used in machine learning for automatic pattern recognition. Types of fault and corresponding numbers of sample are shown in the table below\n",
        "\n",
        "<img src=\"https://docs.google.com/uc?export=download&id=1pw1oJ7plDsTASg_ntI_QSVivQ-tMhlqq\" width=\"500\">\n",
        "\n",
        "\n",
        "The number of samples vary a lot from one category to another. Meanwhile, fault 7 is a special class because it contains all other faults except the first six kinds of fault. In other words, samples in class 7 may have no obvious common characteristics. For every sample, 27 features are recorded, providing evidences for its fault class. All attributes are expressed by integers or real numbers. Detailed information about these 27 independent variables is listed out in the following table.\n",
        "\n",
        "<img src=\"https://docs.google.com/uc?export=download&id=1lAV-mPa2seL9VWkezbaCicnZVwOup2c6\" width=\"500\">\n",
        "\n",
        "\n",
        "Ref: https://www.sciencedirect.com/science/article/pii/S0925231214012193?casa_token=8ZvcrfiUELkAAAAA:Vt2ShomuyzpagA6Su9nSQHzImgti_HHvtK5zuGqgC01It_Xn9UsccPB-5HVtzBonmsYCibDgYQ\n",
        "\n",
        "\n",
        "\n",
        "Ref for the dataset: https://archive.ics.uci.edu/ml/datasets/Steel+Plates+Faults\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qubuPuuLCkg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = ('https://raw.githubusercontent.com/MasoudMiM/ME_364/main/Steel_Plates_Faults/Data.csv')\n",
        "df = pd.read_csv(url,names=['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas', 'X_Perimeter',\n",
        "                            'Y_Perimeter', 'Sum_of_Luminosity', 'Minimum_of_Luminosity', 'Maximum_of_Luminosity',\n",
        "                            'Length_of_Conveyer', 'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n",
        "                            'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index', 'Edges_X_Index',\n",
        "                            'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas', 'Log_X_Index', 'Log_Y_Index',\n",
        "                            'Orientation_Index', 'Luminosity_Index', 'SigmoidOfAreas', 'Pastry', 'Z_Scratch',\n",
        "                            'K_Scratch', 'Stains', 'Dirtiness', 'Bumps', 'Other_Faults'])           \n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_72DwPqwXkK"
      },
      "outputs": [],
      "source": [
        "# Check to see if there are missing values in the dataset\n",
        "df.isnull().sum().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sH8xNtwZdeH8"
      },
      "source": [
        "Step __1__, importing the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5NZbQMUqwsX"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler  # For normalization\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8asJEeYdjg8"
      },
      "source": [
        "Step __2__, defining dependat and independant variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jqdM2CJxtQo_"
      },
      "outputs": [],
      "source": [
        "features = ['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas', 'X_Perimeter',\n",
        "             'Y_Perimeter', 'Sum_of_Luminosity', 'Minimum_of_Luminosity', 'Maximum_of_Luminosity',\n",
        "             'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness']\n",
        "x_data=np.array(df[features])\n",
        "y_data=df['K_Scratch']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spB3qSqjwcqR"
      },
      "outputs": [],
      "source": [
        "df['K_Scratch'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_XEmnxV3wgHE"
      },
      "outputs": [],
      "source": [
        "print('Target variable distribution:')\n",
        "print( df['K_Scratch'].value_counts() )\n",
        "\n",
        "df['K_Scratch'].value_counts().plot(kind='barh')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysiT8ZECdqgD"
      },
      "source": [
        "Step __3__, normalization using MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y03ARncPtWd-"
      },
      "outputs": [],
      "source": [
        "MinMaxscaler = MinMaxScaler()  # define min max scaler\n",
        "x_data_scaled = MinMaxscaler.fit_transform(x_data)  # transform data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQiszaJJdyaT"
      },
      "source": [
        "Step __4__, spliting the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MVdn2apVtYiH"
      },
      "outputs": [],
      "source": [
        "x_train,x_test,y_train,y_test=train_test_split(x_data_scaled,y_data,test_size=0.3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmdeEG5ad1Rc"
      },
      "source": [
        "Step __5__, creating a logistic regression object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-aGOEZ3ettH3"
      },
      "outputs": [],
      "source": [
        "dt = DecisionTreeClassifier(criterion=\"entropy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iadq_2YWd_Gq"
      },
      "source": [
        "Step __6__, fitting the model (training the  model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZFz1ghE_tvL2"
      },
      "outputs": [],
      "source": [
        "dt.fit(x_train,y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZWYSha1eEgi"
      },
      "source": [
        "Step __7__, making predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7fHsaEmtw-V"
      },
      "outputs": [],
      "source": [
        "yhatTest=dt.predict(x_test)\n",
        "yhatTrain=dt.predict(x_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRMgBQdKfQP0"
      },
      "source": [
        "We can look at the classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubsAgazyR1He"
      },
      "outputs": [],
      "source": [
        "dt.classes_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9Y9dqKEfQP0"
      },
      "source": [
        "We can also look at the tree structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MsOyuIFIfQP1"
      },
      "outputs": [],
      "source": [
        "# Method 1\n",
        "text_representation = tree.export_text(dt, max_depth=3, feature_names=features)\n",
        "print(text_representation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQLVuzW_fQP1"
      },
      "outputs": [],
      "source": [
        "# Method 2\n",
        "_, ax = plt.subplots(figsize=(30,30)) # Resize figure\n",
        "tree.plot_tree(dt, max_depth=3, feature_names=features, filled=True, ax=ax);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_jBh2VYgSBD"
      },
      "source": [
        "For the net visualization, you need to install `dtreeviz` library first if it is not installed. Uncomment the cell below to install the library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9kAVvdgVgBrW"
      },
      "outputs": [],
      "source": [
        "#!pip install dtreeviz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oeh9IIWzfQP1"
      },
      "outputs": [],
      "source": [
        "# Method 3\n",
        "from dtreeviz.trees import dtreeviz # remember to load the package\n",
        "\n",
        "dtviz = dtreeviz(dt, x_train, y_train,\n",
        "                target_name=\"target\",\n",
        "                feature_names=features,\n",
        "                class_names=('No Fault', 'Faulty'))\n",
        "\n",
        "dtviz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EwTMzzQhuCb9"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.metrics import jaccard_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ciPax8aPuLtd"
      },
      "outputs": [],
      "source": [
        "acc_scoreTrain = accuracy_score(y_train,yhatTrain)\n",
        "acc_scoreTest = accuracy_score(y_test,yhatTest)\n",
        "print(f'The accuracy for training data is {acc_scoreTrain:0.3f}')\n",
        "print(f'The accuracy for the test data is {acc_scoreTest:0.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mf9zrExWuNDd"
      },
      "outputs": [],
      "source": [
        "J_scoreTrain = jaccard_score(y_train,yhatTrain)\n",
        "J_scoreTest = jaccard_score(y_test,yhatTest)\n",
        "print(f'Jaccard index for training data is {J_scoreTrain:0.3f}')\n",
        "print(f'Jaccard index for the test data is {J_scoreTest:0.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EY_cEHR6uOxc"
      },
      "outputs": [],
      "source": [
        "F_scoreTrain = f1_score(y_train,yhatTrain)\n",
        "F_scoreTest = f1_score(y_test,yhatTest)\n",
        "print(f'F-score for training data is {F_scoreTrain:0.3f}')\n",
        "print(f'F-score for the test data is {F_scoreTest:0.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTAdsZLkwOY5"
      },
      "outputs": [],
      "source": [
        "LogLossTrain = log_loss(y_train,yhatTrain)\n",
        "LogLossTest = log_loss(y_test,yhatTest)\n",
        "print(f'Log Loss for training data is {LogLossTrain:0.3f}')\n",
        "print(f'Log loss for the test data is {LogLossTest:0.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7XNXR2wV0peK"
      },
      "outputs": [],
      "source": [
        "print('Confusion matrix for training data')\n",
        "CM_scoreTrain = confusion_matrix(y_train,yhatTrain)   # possible option normalize='true'\n",
        "print(CM_scoreTrain)\n",
        "\n",
        "print(40*'-')\n",
        "\n",
        "print('Confusion matrix for test data')\n",
        "CM_scoreTest = confusion_matrix(y_test,yhatTest)   # possible option normalize='true'\n",
        "print(CM_scoreTest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ZN3V_lQ01D-"
      },
      "outputs": [],
      "source": [
        "dispTr = ConfusionMatrixDisplay(CM_scoreTrain,display_labels=['No Fault','Fault']) # \n",
        "dispTr.plot()\n",
        "\n",
        "dispTs = ConfusionMatrixDisplay(CM_scoreTest,display_labels=['No Fault','Fault'])\n",
        "dispTs.plot()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "14_DT.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
