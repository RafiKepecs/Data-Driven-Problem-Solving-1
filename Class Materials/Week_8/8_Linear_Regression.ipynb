{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOwmiJ6bHYZx"
      },
      "source": [
        "# Linear Regression\n",
        "\n",
        "## Table of Contents\n",
        "\n",
        "1. [**Introduction**](#Intro)   \n",
        "2. [**Simple Linear Regression**](#SLR)\n",
        "\n",
        "  2.1 [**Model Development**](#ModelDevSLR) \n",
        "\n",
        "  2.2 [**Model Evaluation**](#ModelEvalSLR)\n",
        "\n",
        "3. [**Multiple Linear Regression**](#MLR)\n",
        "\n",
        "  3.1 [**Model Development**](#ModelDevMLR)\n",
        "\n",
        "  3.2 [**Model Evaluation**](#ModelEvalMLR)\n",
        "\n",
        "4. [**Final Comments**](#FinalComments)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4Nb5i9oHe6A"
      },
      "source": [
        "## 1. Introduction <a name=\"Intro\"></a>\n",
        "\n",
        "__Linear Regression__ is a bread-and-butter modeling technique that should serve as your baseline approach to building data-driven models. These models are typically easy to build, straighforward to interpret, and often do quite well in practice.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cGXWXjlhxk5"
      },
      "source": [
        "## 2. Simple Linear Regression <a name=\"SLR\"></a>\n",
        "\n",
        "Simple linear regression refers to one independant variable to make a prediction. Generally, we seek to find the best values for $\\omega$'s in $f(\\text{x})=\\omega_o+\\omega_1x_1$, which can be found as:\n",
        "\n",
        "\n",
        "$\\omega_1=\\frac{\\sum_{i=1}^{m}(x^{(i)}-\\bar{x})(y^{(i)}-\\bar{y})}{\\sum_{i=1}^{m}(x^{(i)}-\\bar{x})^2}=\\frac{C_{xy}}{C_{xx}}$\n",
        "\n",
        "$\\omega_0=\\bar{y}-\\omega_1\\bar{x}_1=E[y]-\\omega_1E[x]$\n",
        "\n",
        "where $C_{xy}=Cov[X,Y]$ and $C_{xx}=Cov[X,Y]=V[X]$\n",
        "\n",
        "__Note__: You can find these coefficients using least squares method: https://www.real-statistics.com/regression/least-squares-method/least-squares-method-detailed/\n",
        "\n",
        "We are going to use scikit-learn (https://scikit-learn.org), which is one of the most commonly used machine learning libraries in Python.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVecOvumMDiX"
      },
      "source": [
        "### 2.1 Model Development <a name=\"ModelDevSLR\"></a>\n",
        "\n",
        "Here are the steps to implement simple linear regression in Python using `scikit-learn`.\n",
        "\n",
        "__1.__ Import linear regression and train_test_split funcions from `scikit_learn` library:\n",
        "```python\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "```\n",
        "\n",
        "__2.__ Define independent variable (feature) and dependent variable (target variable) from data set:\n",
        "```python\n",
        "x_data=np.array(df[['column1']])\n",
        "y_data=np.array(df[['column2']])\n",
        "```\n",
        "\n",
        "__3.__ Split the data into train and test sets while determining the train/test size split: `x_train,x_test,y_train,y_test=train_test_split(x_data, y_data, test_size=0.2, shuffle=True)`\n",
        "\n",
        "\n",
        "__4.__ Create an instance of linear regression using the constructor: `lm = LinearRegression() `\n",
        "\n",
        "\n",
        "__5.__ Use the fit function to fit the model to the training data and find the coefficients $\\omega_o$ and $\\omega_1$: `lm.fit(x_train,y_train)`\n",
        "\n",
        "__6.__ Make prediction using the test data: `yhat=lm.predict(x_test)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmV_M6WWC1O6"
      },
      "source": [
        "Let's use our 3D printer data set. The aim of the study was to determine how much of the adjustment parameters in 3d printers affect the print quality, accuracy and strength. There are nine setting parameters and three measured output parameters.\n",
        "\n",
        "Setting Parameters:\n",
        "\n",
        "•\tLayer Height (mm)\n",
        "\n",
        "•\tWall Thickness (mm)\n",
        "\n",
        "•\tInfill Density (%)\n",
        "\n",
        "•\tInfill Pattern ()\n",
        "\n",
        "•\tNozzle Temperature (ºC)\n",
        "\n",
        "•\tBed Temperature (ºC)\n",
        "\n",
        "•\tPrint Speed (mm/s)\n",
        "\n",
        "•\tMaterial ()\n",
        "\n",
        "•\tFan Speed (mm/s)\n",
        "\n",
        "\n",
        "Output Parameters: (Measured)\n",
        "\n",
        "•\tRoughness (µm)\n",
        "\n",
        "•\tTensile (ultimate) Strenght (MPa)\n",
        "\n",
        "•\tElongation (%) \n",
        "\n",
        "This work is based on the Ultimaker S5 3D printer settings and filaments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gmp1y4HIgVRk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/MasoudMiM/ME_364/main/3D_Printer_Data/3DPrinterDataset.csv'   # Link to the 3D printer data set\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Dataset is now stored in a Pandas's Dataframe\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gir99y8mFeBM"
      },
      "source": [
        "Typically, we need to first do an exploratory data analysis before we start developing a model. However, here we assume that some data cleaning and exploratory data analysis has been done on the data set. Let's just take a look at layer height and roughness."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SqsR9VeUXoWG"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rc('font',size=20)\n",
        "# OR you could use\n",
        "#plt.rcParams.update({'font.size':20})\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.scatterplot(data=df, x='layer_height', y='roughness', \n",
        "                s=100, color='r');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGIZwE3uWS6u"
      },
      "source": [
        "Let's develop a simple linear regression model, considering independent variable \"layer height\" and dependent variable \"roughness\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MH3C0JHZP8F"
      },
      "outputs": [],
      "source": [
        "# importing required functions\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMSUlG27ZRDd"
      },
      "outputs": [],
      "source": [
        "# defining the I.V. (feature) and Target Variable (Dependent variable)\n",
        "import numpy as np\n",
        "\n",
        "x_datal=np.array(df[['layer_height']])   # I.V.\n",
        "y_datal=np.array(df[['roughness']])      # Target Variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOj4przwZfq1"
      },
      "outputs": [],
      "source": [
        "# Splitting the data into train and test 80/20\n",
        "x_trainl,x_testl,y_trainl,y_testl=train_test_split(\n",
        "    x_datal,y_datal, test_size=0.2, shuffle=True, random_state=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6oMJZLQecg9"
      },
      "outputs": [],
      "source": [
        "# Extra Step!\n",
        "# Looking at the training and test data distribution\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.scatter(x_trainl,y_trainl, s=100, color='r', label='Training Data')\n",
        "plt.scatter(x_testl,y_testl, s=100, color='b',label='Test Data')\n",
        "plt.xlabel('Layer Height (mm)')\n",
        "plt.ylabel('Roughness (µm)')\n",
        "plt.legend(loc='best');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPQ-lLMoZ-fD"
      },
      "outputs": [],
      "source": [
        "# Define the instance of linear regression\n",
        "lml = LinearRegression()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07aZMDZVaZMx"
      },
      "outputs": [],
      "source": [
        "# Fitting the model to the training data\n",
        "lml.fit(x_trainl,y_trainl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-Jdxg6DdOrL"
      },
      "outputs": [],
      "source": [
        "# reporting the values of weights\n",
        "w0l=lml.intercept_[0]  # w_0\n",
        "w1l=lml.coef_[0][0]    # W-1\n",
        "print(f'w_0={w0l:.3f} and w_1={w1l:.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPQaYxxRfVfn"
      },
      "source": [
        "Now, we can make predictions using our model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHEFoPfYfeLm"
      },
      "outputs": [],
      "source": [
        "# making prediction\n",
        "yhatl = lml.predict(x_testl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also look at the actual values and the predicted values together."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ifVUWGfUkCD5"
      },
      "outputs": [],
      "source": [
        "np.column_stack([y_testl, yhatl])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAw76r8AMFaG"
      },
      "source": [
        "### 2.2 Model Evaluation <a name=\"ModelEvalSLR\"></a>\n",
        "\n",
        "There are multiple available evaluation metrics for regression:\n",
        "\n",
        "![alt text](https://docs.google.com/uc?export=download&id=1ZFL4VHPc0IhVi-rAX9HUisAladfdDkBL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mmG-ibgjI0v"
      },
      "source": [
        "Here is how you can evaluate your model using Mean Absolute Error (MAE), Mean Squared Error (MSE) and R-Squared (R$^2$). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TO7LwMKLjgbn"
      },
      "outputs": [],
      "source": [
        "# Mean Squared Error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "MSE=mean_squared_error(y_testl, yhatl)\n",
        "print(f'The value of mean squared error is: {MSE:.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jv8av_v5klmd"
      },
      "outputs": [],
      "source": [
        "# R2 score\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "r2score = r2_score(y_testl, yhatl)\n",
        "print(f'The value of R2 is: {r2score:.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4AaDqULl7H-"
      },
      "outputs": [],
      "source": [
        "# Mean Absolute Error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "MAE=mean_absolute_error(y_testl,yhatl)\n",
        "print(f'The value of mean absolute error is: {MAE:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moXzaNa3orKq"
      },
      "source": [
        "We can also visually inspect the fit line and see how much it represents our data points."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmKpB39apn6C"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10,10))                       # set the size of the figure\n",
        "plt.rc('font',size=15)                            # set the font size\n",
        "\n",
        "# Plotting the training data\n",
        "plt.scatter(x_trainl, y_trainl,s=100,color='red',label='Training Data')\n",
        "\n",
        "# Plotting the test data\n",
        "plt.scatter(x_testl, y_testl,s=100,color='blue', label='Test Data')\n",
        "\n",
        "# Plotting the fitted line\n",
        "xplot=np.linspace(0,0.2,num=100)\n",
        "yplot=w0l+w1l*xplot\n",
        "plt.plot(xplot, yplot, lw=4,color='green', label='Fitted Line')\n",
        "\n",
        "# Labling and putting legend\n",
        "plt.xlabel('Layer Height (mm)')\n",
        "plt.ylabel('Roughness (µm)')\n",
        "plt.grid(True)\n",
        "plt.legend(loc='best');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKf_z0jDzIP_"
      },
      "source": [
        "## 3. Multiple Linear Regression <a name=\"MLR\"></a>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGxUiiMl7oLn"
      },
      "source": [
        "### 3.1 Model Development <a name=\"ModelDevMLR\"></a>\n",
        "\n",
        "The fortunate thing is that multiple linear regression is the extension of simple linear regression model and can be implemented using `scikit-learn` library in a similar manner.\n",
        "\n",
        "Here are the steps to implement multiple linear regression in Python using `scikit-learn`.\n",
        "\n",
        "__1.__ Import linear regression and train_test_split funcions from `scikit_learn` library:\n",
        "```python\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "```\n",
        "\n",
        "__2.__ Define dependant (Target Variable) and independent variables (Features) from data set:\n",
        "```python\n",
        "x_data=np.array(df[['column(1)','column(2)',...]]) # Features or I.V.s\n",
        "y_data=np.array(df[['column']]) # Target or D.V.\n",
        "```\n",
        "\n",
        "__3.__ Split the data into train and test sets while determining the test train/test size: `x_train,x_test,y_train,y_test=train_test_split(x_data, y_data, test_size=0.2, shuffle=True)`\n",
        "\n",
        "\n",
        "__4.__ Create a linear regression object using the constructor: `lm = LinearRegression() `\n",
        "\n",
        "\n",
        "__5.__ Use the fit function to fit the model to the training data and find the coefficients $\\omega_o$, $\\omega_1$, $\\omega_2$,...: `lm.fit(x_train, y_train)`\n",
        "\n",
        "__6.__ Then, make prediction using the test data: `yhat=lm.predict(x_test)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTcPWiIp-Ube"
      },
      "source": [
        "Let's start with two variables \"layer height\" and \"infill density\" as features (independent variables) and \"roughness\" as the target variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vuTxcN_tHTUz"
      },
      "outputs": [],
      "source": [
        "# importing required functions\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# defining the I.V. and Target Variable (D.V.)\n",
        "x_datam=np.array(df[['layer_height','infill_density']])\n",
        "y_datam=np.array(df[['roughness']])\n",
        "\n",
        "# Splitting the data into train and test 80/20\n",
        "x_trainm, x_testm, y_trainm, y_testm=train_test_split(x_datam, y_datam, test_size=0.2, shuffle=True, random_state=10)\n",
        "\n",
        "# Define the linear regression object\n",
        "lmm = LinearRegression()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRbwrPKk9T-F"
      },
      "source": [
        "Let's fit the model now"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ksv2ETzv9TBv"
      },
      "outputs": [],
      "source": [
        "# Fitting the model to the training data\n",
        "lmm.fit(x_trainm, y_trainm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2mWPIo17BBdC"
      },
      "outputs": [],
      "source": [
        "# reporting the values of weights\n",
        "w0m=lmm.intercept_[0]  # w_0\n",
        "w1m=lmm.coef_[0,0]     # w_1\n",
        "w2m=lmm.coef_[0,1]     # w_2\n",
        "print(f'w_0={w0m:0.2f}, w_1= {w1m:.2f} and w2={w2m:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwTERFry9Sgi"
      },
      "source": [
        "Now, we can make predictions using our model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4en9ehMCKTR"
      },
      "outputs": [],
      "source": [
        "# making prediction\n",
        "yhatm = lmm.predict(x_testm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, comparing the actual values and predicted values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSGO_OvJbfoa"
      },
      "outputs": [],
      "source": [
        "np.column_stack([y_testm, yhatm])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAYas-77CSta"
      },
      "source": [
        "### 3.2 Model Evaluation <a name=\"ModelEvalMLR\"></a>\n",
        "\n",
        "We can evluate our model using the previously introduced evaluation metrics such as MSE, MAE, R$^2$, ... "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_CfkNFSCM8d"
      },
      "outputs": [],
      "source": [
        "# Mean Squared Error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "MSEm = mean_squared_error(y_testm, yhatm)\n",
        "print(f'The value of mean squared error is: {MSEm:.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gN2nzTpjFA5j"
      },
      "outputs": [],
      "source": [
        "# R2\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "r2scorem = r2_score(y_testm, yhatm)\n",
        "print(f'The value of R2 is: {r2scorem:.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFycp0g3FMpR"
      },
      "outputs": [],
      "source": [
        "# Mean Absolute Error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "MAEm=mean_absolute_error(y_testm, yhatm)\n",
        "print(f'The value of mean absolute error is: {MAEm:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bY9yI2yikmkO"
      },
      "source": [
        "<font color=blue>__NOTE__</font>: We can actually see that the previous model, i.e. __simple linear regression__, had a __better__ performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeJLDAF-O3vt"
      },
      "source": [
        "We can look at the data points along with the fit plane"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a00N2FPSGBvy"
      },
      "outputs": [],
      "source": [
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure(figsize=(15,15))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "plt.rc('font',size=12)\n",
        "\n",
        "xt =x_trainm[:,0]\n",
        "yt =x_trainm[:,1]\n",
        "zt =y_trainm[:,0]\n",
        "\n",
        "ax.scatter(xt, yt, zt, c='r', marker='o',s=100, label='Training Data')\n",
        "\n",
        "xs =x_testm[:,0]\n",
        "ys =x_testm[:,1]\n",
        "zs =y_testm[:,0]\n",
        "\n",
        "ax.scatter(xs, ys, zs, c='b', marker='o',s=100, label='Test Data')\n",
        "\n",
        "xsrf = np.linspace(0.025, 0.2, 50)\n",
        "ysrf = np.linspace(10,100, 50)\n",
        "X, Y = np.meshgrid(xsrf, ysrf)\n",
        "Z = w0m+w1m*X+w2m*Y\n",
        "ax.contour3D(X, Y, Z, 100, cmap='binary')\n",
        "\n",
        "ax.set_xlabel('Layer Height (mm)')\n",
        "ax.set_ylabel('Infil Density (%)')\n",
        "ax.set_zlabel('Roughness (µm)')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owU1HqWhp16i"
      },
      "source": [
        "What if we add `nozzle_temperature` as another feaure to our model? Let's see if it can improve the performance of our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2eZA_QNGlvqN"
      },
      "outputs": [],
      "source": [
        "# defining the I.V. and Target Variable (Dependat variable)\n",
        "x_datam2=np.array(df[['layer_height','infill_density','nozzle_temperature']])\n",
        "y_datam2=np.array(df[['roughness']])\n",
        "\n",
        "# Splitting the data into train and test 80/20\n",
        "x_trainm2,x_testm2,y_trainm2,y_testm2 = train_test_split(x_datam2,y_datam2,test_size=0.2,shuffle=True, random_state=20)\n",
        "\n",
        "# Define the linear regression object\n",
        "lmm2 = LinearRegression()\n",
        "\n",
        "# Fitting the model to the training data\n",
        "lmm2.fit(x_trainm2,y_trainm2)\n",
        "\n",
        "# reporting the values of weights\n",
        "w0m2=lmm2.intercept_[0]\n",
        "w1m2=lmm2.coef_[0,0]\n",
        "w2m2=lmm2.coef_[0,1]\n",
        "w3m2=lmm2.coef_[0,2]\n",
        "print(f'w_0= {w0m2:.2f}, w_1={w1m2:.2f}, w_2={w2m2:.2f}, w_3={w3m2:.2f}')\n",
        "\n",
        "# making prediction\n",
        "yhatm2 = lmm2.predict(x_testm2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jXocgUyUo-b7"
      },
      "outputs": [],
      "source": [
        "MSEm2=mean_squared_error(y_testm2,yhatm2)\n",
        "print(f'The value of mean squared error is: {MSEm2:.2f}')\n",
        "\n",
        "r2scorem2 = r2_score(y_testm2,yhatm2)\n",
        "print(f'The value of R2 is: {r2scorem2:.2f}')\n",
        "\n",
        "MAEm2=mean_absolute_error(y_testm2,yhatm2)\n",
        "print(f'The value of mean absolute error is: {MAEm2:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's compare the values of $R^2$, MSE, and MAE for all models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "MAEs = [MAE, MAEm, MAEm2]\n",
        "MSEs = [MSE, MSEm, MSEm2]\n",
        "R2s = [r2score, r2scorem, r2scorem2]\n",
        "names = ['Simple', 'Multi-1', 'Multi-2']\n",
        "fig, axes=plt.subplots(nrows=1, ncols=3, figsize=(15,4))\n",
        "axes[0].bar(names, MAEs)\n",
        "axes[0].set_title('MAEs')\n",
        "axes[1].bar(names, MSEs)\n",
        "axes[1].set_title('MSEs')\n",
        "axes[2].bar(names, R2s)\n",
        "axes[2].set_title(f'R$^2$ Scores');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkLMkol_P31e"
      },
      "source": [
        "## 3. Final Comment <a name=\"FinalComments\"></a>\n",
        "\n",
        "When we are developing a model using linear regression, we need to determine the best fit. To do so, we look at a combination of \n",
        "\n",
        "- Do the predicted values make sense?\n",
        "\n",
        "- Visualization\n",
        "\n",
        "- Evaluation Metrics\n",
        "\n",
        "- Comparing models"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "8_Linear_Regression.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
